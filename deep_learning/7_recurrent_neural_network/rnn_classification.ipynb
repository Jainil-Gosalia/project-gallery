{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "61effed5-1c9f-40d0-bf0c-209be4656109",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from datasets import load_dataset\n",
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23f588a1-ee0a-4ce3-b48f-df2c6d51fdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Load dataset and build vocab\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "train_texts = dataset['train']['text']\n",
    "train_labels = dataset['train']['label']\n",
    "\n",
    "test_texts = dataset['test']['text']\n",
    "test_labels = dataset['test']['label']\n",
    "\n",
    "def build_vocab(texts, max_size=10000):\n",
    "    words = []\n",
    "    for text in texts:\n",
    "        words.extend(text.lower().split())\n",
    "    freq = Counter(words)\n",
    "    vocab = {word: i+1 for i, (word, _) in enumerate(freq.most_common(max_size))}\n",
    "    return vocab\n",
    "\n",
    "vocab = build_vocab(train_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1f0df4ea-521e-4b9a-a5ef-036439fc5f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Encode texts to fixed-length sequences\n",
    "def encode(text, vocab, max_len=100):\n",
    "    tokens = text.lower().split()\n",
    "    idxs = [vocab.get(token, 0) for token in tokens]  # 0 for unknown words\n",
    "    if len(idxs) < max_len:\n",
    "        idxs += [0] * (max_len - len(idxs))\n",
    "    else:\n",
    "        idxs = idxs[:max_len]\n",
    "    return idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e23dd477-0cbc-4746-8909-68e4b009827e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Custom dataset class\n",
    "class TextDataset(Dataset):\n",
    "    def __init__(self, texts, labels, vocab):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.vocab = vocab\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        x = torch.tensor(encode(self.texts[idx], self.vocab), dtype=torch.long)\n",
    "        y = torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "        return x, y\n",
    "\n",
    "train_dataset = TextDataset(train_texts, train_labels, vocab)\n",
    "test_dataset = TextDataset(test_texts, test_labels, vocab)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2500ddc1-340e-4f9f-b279-88d177a49c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Define model\n",
    "class RNNClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_dim=50, hidden_dim=64, output_dim=2):\n",
    "        super().__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size + 1, embed_dim, padding_idx=0)\n",
    "        self.rnn = nn.RNN(embed_dim, hidden_dim, batch_first=True)\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        out, _ = self.rnn(x)\n",
    "        out = self.dropout(out[:, -1, :])  # apply dropout on last hidden state\n",
    "        out = self.fc(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "model = RNNClassifier(vocab_size=len(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bcbaf341-f3a8-40fd-84a9-fa7bcb782d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b69bdeb8-f914-4d34-acf0-d6beaf52aab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Training loop\n",
    "def train_epoch(model, loader, optimizer, criterion, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x_batch, y_batch in loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(x_batch)\n",
    "        loss = criterion(outputs, y_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    return total_loss / len(loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a581c681-f02f-474e-8c0d-137d6d49e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. Evaluation function\n",
    "def evaluate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x_batch, y_batch in loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            outputs = model(x_batch)\n",
    "            loss = criterion(outputs, y_batch)\n",
    "            total_loss += loss.item()\n",
    "            \n",
    "            preds = outputs.argmax(dim=1)\n",
    "            correct += (preds == y_batch).sum().item()\n",
    "            total += y_batch.size(0)\n",
    "    return total_loss / len(loader), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "49ce7179-13bb-49d4-9f68-37ec1dea2409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train loss=0.6999, Val loss=0.6939, Val acc=0.5104\n",
      "Epoch 2: Train loss=0.6918, Val loss=0.6928, Val acc=0.5088\n",
      "Epoch 3: Train loss=0.6924, Val loss=0.6923, Val acc=0.5171\n",
      "Epoch 4: Train loss=0.6894, Val loss=0.6934, Val acc=0.5291\n",
      "Epoch 5: Train loss=0.6795, Val loss=0.6922, Val acc=0.5330\n",
      "Epoch 6: Train loss=0.6635, Val loss=0.6770, Val acc=0.5831\n",
      "Epoch 7: Train loss=0.6595, Val loss=0.6910, Val acc=0.5351\n",
      "Epoch 8: Train loss=0.6658, Val loss=0.7007, Val acc=0.5666\n",
      "Epoch 9: Train loss=0.6367, Val loss=0.6885, Val acc=0.5633\n",
      "Epoch 10: Train loss=0.6374, Val loss=0.7011, Val acc=0.5349\n",
      "Epoch 11: Train loss=0.6027, Val loss=0.7106, Val acc=0.5426\n",
      "Epoch 12: Train loss=0.6000, Val loss=0.7009, Val acc=0.5878\n",
      "Epoch 13: Train loss=0.5529, Val loss=0.6899, Val acc=0.6190\n",
      "Epoch 14: Train loss=0.6025, Val loss=0.7231, Val acc=0.5209\n",
      "Epoch 15: Train loss=0.5885, Val loss=0.6958, Val acc=0.6076\n",
      "Epoch 16: Train loss=0.5840, Val loss=0.7303, Val acc=0.5466\n",
      "Epoch 17: Train loss=0.5966, Val loss=0.6951, Val acc=0.5988\n",
      "Epoch 18: Train loss=0.5537, Val loss=0.7365, Val acc=0.5910\n",
      "Epoch 19: Train loss=0.5301, Val loss=0.7035, Val acc=0.6172\n",
      "Epoch 20: Train loss=0.5614, Val loss=0.7679, Val acc=0.5949\n",
      "Epoch 21: Train loss=0.5372, Val loss=0.7370, Val acc=0.5428\n",
      "Epoch 22: Train loss=0.5443, Val loss=0.7281, Val acc=0.5872\n",
      "Epoch 23: Train loss=0.5377, Val loss=0.7496, Val acc=0.5457\n",
      "Epoch 24: Train loss=0.5293, Val loss=0.7492, Val acc=0.5855\n",
      "Epoch 25: Train loss=0.5010, Val loss=0.7576, Val acc=0.6031\n",
      "Epoch 26: Train loss=0.4915, Val loss=0.7739, Val acc=0.5859\n",
      "Epoch 27: Train loss=0.4667, Val loss=0.7478, Val acc=0.6241\n",
      "Epoch 28: Train loss=0.4821, Val loss=0.7738, Val acc=0.6134\n",
      "Epoch 29: Train loss=0.5368, Val loss=0.7768, Val acc=0.5546\n",
      "Epoch 30: Train loss=0.4987, Val loss=0.7886, Val acc=0.5777\n",
      "Epoch 31: Train loss=0.4722, Val loss=0.7534, Val acc=0.6073\n",
      "Epoch 32: Train loss=0.4572, Val loss=0.7959, Val acc=0.5922\n",
      "Epoch 33: Train loss=0.4333, Val loss=0.7844, Val acc=0.6225\n",
      "Epoch 34: Train loss=0.4396, Val loss=0.8169, Val acc=0.6089\n",
      "Epoch 35: Train loss=0.4249, Val loss=0.8269, Val acc=0.5680\n",
      "Epoch 36: Train loss=0.4172, Val loss=0.7650, Val acc=0.6341\n",
      "Epoch 37: Train loss=0.4060, Val loss=0.7954, Val acc=0.6141\n",
      "Epoch 38: Train loss=0.4183, Val loss=0.7283, Val acc=0.6378\n",
      "Epoch 39: Train loss=0.4081, Val loss=0.7826, Val acc=0.6219\n",
      "Epoch 40: Train loss=0.3987, Val loss=0.8956, Val acc=0.5327\n",
      "Epoch 41: Train loss=0.4607, Val loss=0.8240, Val acc=0.6149\n",
      "Epoch 42: Train loss=0.3854, Val loss=0.7450, Val acc=0.6533\n",
      "Epoch 43: Train loss=0.4534, Val loss=0.7803, Val acc=0.5578\n",
      "Epoch 44: Train loss=0.4841, Val loss=0.8254, Val acc=0.5722\n",
      "Epoch 45: Train loss=0.4448, Val loss=0.8486, Val acc=0.5856\n",
      "Epoch 46: Train loss=0.4248, Val loss=0.7973, Val acc=0.5987\n",
      "Epoch 47: Train loss=0.3794, Val loss=0.8351, Val acc=0.6163\n",
      "Epoch 48: Train loss=0.3763, Val loss=0.8772, Val acc=0.6039\n",
      "Epoch 49: Train loss=0.3576, Val loss=0.8494, Val acc=0.6206\n",
      "Epoch 50: Train loss=0.3375, Val loss=0.8889, Val acc=0.6374\n"
     ]
    }
   ],
   "source": [
    "# 8. Run training\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "epochs = 50\n",
    "for epoch in range(epochs):\n",
    "    train_loss = train_epoch(model, train_loader, optimizer, criterion, device)\n",
    "    val_loss, val_acc = evaluate(model, test_loader, criterion, device)\n",
    "    print(f\"Epoch {epoch+1}: Train loss={train_loss:.4f}, Val loss={val_loss:.4f}, Val acc={val_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "743f0113-6af1-47e1-8299-d3e391fae283",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 63.74%\n"
     ]
    }
   ],
   "source": [
    "test_acc = evaluate(model, test_loader, criterion, device)\n",
    "print(f\"Test Accuracy: {round(test_acc[1] * 100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
