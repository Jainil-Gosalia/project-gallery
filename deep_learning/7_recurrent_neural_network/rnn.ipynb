{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "92a6ee0b-32a8-4a96-9f1b-eac316a2e672",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a2dc330c-424a-4651-acea-8b65f75ebe5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-05-22 15:34:20--  https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1115394 (1.1M) [text/plain]\n",
      "Saving to: ‘input.txt’\n",
      "\n",
      "input.txt           100%[===================>]   1.06M  --.-KB/s    in 0.08s   \n",
      "\n",
      "2025-05-22 15:34:20 (12.9 MB/s) - ‘input.txt’ saved [1115394/1115394]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Download Tiny Shakespeare or use your own plain text file\n",
    "!wget https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt -O input.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5c57969-2f4f-4961-98ba-69dc0dbab509",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique chars: 65\n"
     ]
    }
   ],
   "source": [
    "# Vocab\n",
    "with open(\"input.txt\", \"r\") as f:\n",
    "    text = f.read()\n",
    "\n",
    "vocab = sorted(set(text))\n",
    "vocab_size = len(vocab)\n",
    "print(f\"Unique chars: {vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69a2fc79-157e-4d3e-840e-0559c79d2ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_idx = {ch: i for i, ch in enumerate(vocab)}\n",
    "idx_to_char = {i: ch for ch, i in char_to_idx.items()}\n",
    "encoded_text = torch.tensor([char_to_idx[c] for c in text], dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3124ad62-b665-4588-af19-f9de81e79231",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch(seq_len=64, batch_size=1):\n",
    "    starts = [random.randint(0, len(encoded_text) - seq_len - 1) for _ in range(batch_size)]\n",
    "    x = torch.stack([encoded_text[s:s+seq_len] for s in starts])\n",
    "    y = torch.stack([encoded_text[s+1:s+seq_len+1] for s in starts])\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f348694-441c-4cff-80fe-7b44d7996756",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Manual RNN Cell\n",
    "\n",
    "class MyRNNCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.W_ih = nn.Parameter(torch.randn(hidden_size, input_size) * 0.01)\n",
    "        self.W_hh = nn.Parameter(torch.randn(hidden_size, hidden_size) * 0.01)\n",
    "        self.b_ih = nn.Parameter(torch.zeros(hidden_size))\n",
    "        self.b_hh = nn.Parameter(torch.zeros(hidden_size))\n",
    "\n",
    "    def forward(self, x, h_prev):\n",
    "        return torch.tanh(x @ self.W_ih.T + self.b_ih + h_prev @ self.W_hh.T + self.b_hh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6982da60-801b-438f-91f0-c3d25752db19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# RNN From Scratch\n",
    "\n",
    "class CharRNN_Custom(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embed = nn.Embedding(vocab_size, vocab_size)  # one-hot style\n",
    "        self.rnn_cell = MyRNNCell(vocab_size, hidden_size)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        batch_size, seq_len = x.shape\n",
    "        if h is None:\n",
    "            h = torch.zeros(batch_size, self.hidden_size)\n",
    "        logits = []\n",
    "        for t in range(seq_len):\n",
    "            x_t = self.embed(x[:, t])\n",
    "            h = self.rnn_cell(x_t, h)\n",
    "            logits.append(self.fc(h))\n",
    "        return torch.stack(logits, dim=1), h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3ddd546b-afdf-4692-901d-4613a8e8b842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PyTorch nn.RNN Version\n",
    "\n",
    "class CharRNN_PyTorch(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_size, num_layers=1):\n",
    "        super().__init__()\n",
    "        self.embed = nn.Embedding(vocab_size, vocab_size)\n",
    "        self.rnn = nn.RNN(vocab_size, hidden_size, num_layers=num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, vocab_size)\n",
    "\n",
    "    def forward(self, x, h=None):\n",
    "        x = self.embed(x)\n",
    "        out, h = self.rnn(x, h)\n",
    "        logits = self.fc(out)\n",
    "        return logits, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62d6c7c2-5d1e-4a9c-9d4f-d0c049ebfe99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Function (shared)\n",
    "\n",
    "def train_model(model, steps=3000, print_every=500, lr=1e-3):\n",
    "    model.train()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    loss_fn = nn.CrossEntropyLoss()\n",
    "    for step in range(steps):\n",
    "        x, y = get_batch()\n",
    "        logits, _ = model(x)\n",
    "        loss = loss_fn(logits.view(-1, vocab_size), y.view(-1))\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if step % print_every == 0:\n",
    "            print(f\"Step {step}, Loss: {loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c5a9116-1453-4307-9bad-087dd85ae41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample Function\n",
    "\n",
    "def sample(model, start_char=\"T\", length=200):\n",
    "    model.eval()\n",
    "    idx = char_to_idx[start_char]\n",
    "    input = torch.tensor([[idx]])\n",
    "    h = None\n",
    "    result = [start_char]\n",
    "    for _ in range(length):\n",
    "        logits, h = model(input, h)\n",
    "        probs = F.softmax(logits[:, -1], dim=-1)\n",
    "        idx = torch.multinomial(probs, num_samples=1).item()\n",
    "        input = torch.tensor([[idx]])\n",
    "        result.append(idx_to_char[idx])\n",
    "    return ''.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78adce3d-dd8e-47be-b8f4-1da33dccf219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RNN from scratch...\n",
      "Step 0, Loss: 4.1850\n",
      "Step 500, Loss: 2.6011\n",
      "Step 1000, Loss: 2.4569\n",
      "Step 1500, Loss: 2.5476\n",
      "Step 2000, Loss: 1.9809\n",
      "Step 2500, Loss: 1.8580\n"
     ]
    }
   ],
   "source": [
    "# Train and Compare\n",
    "print(\"Training RNN from scratch...\")\n",
    "custom_model = CharRNN_Custom(vocab_size, hidden_size=128)\n",
    "train_model(custom_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b02d60d-3ec3-4ce1-b90b-2539219e0a4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated by custom RNN:\n",
      "Thour ione grair lon, I'll sow!\n",
      "\n",
      "Fimcel to rulllatinge bowd be,\n",
      "Home his prouriof upalt, tout, not will all prite ot would arout bot thall mne's in bene, thou might his ofe-\n",
      "Bull wirs: turch-dost ona t\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerated by custom RNN:\")\n",
    "print(sample(custom_model, \"T\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63b22915-4c3f-4d3e-9f02-79dfd0a3d5d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training nn.RNN model...\n",
      "Step 0, Loss: 4.1594\n",
      "Step 500, Loss: 2.0742\n",
      "Step 1000, Loss: 1.8567\n",
      "Step 1500, Loss: 1.9986\n",
      "Step 2000, Loss: 1.8591\n",
      "Step 2500, Loss: 1.9798\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nTraining nn.RNN model...\")\n",
    "pytorch_model = CharRNN_PyTorch(vocab_size, hidden_size=128)\n",
    "train_model(pytorch_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b29f4176-4eaa-4222-b317-b2b3befb7673",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Generated by nn.RNN:\n",
      "TAM:\n",
      "Chid, I love,\n",
      "Coich for gesielt the al'ust Ge! ast have but atbere' nigh,\n",
      "Scems oulds hers all taces heence.\n",
      "WhPreale.\n",
      "Will kays the bich beso pousiundoun thil uf cabsay exvathour deat, bus llope \n"
     ]
    }
   ],
   "source": [
    "print(\"\\nGenerated by nn.RNN:\")\n",
    "print(sample(pytorch_model, \"T\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
