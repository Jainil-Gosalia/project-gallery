{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "786b01b6-9845-4d78-9a24-3c1dd4c9c660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40bbc617-5ce0-4156-875a-3263c3ff7b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ReAct Agent Loop Components \n",
    "\n",
    "# Thought (Reason)\n",
    "# Action (Tools)\n",
    "# Observation (Tool Output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be5d6240-02d4-4975-af56-4a1926a525de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02f4b28c0003493ebf63b67f7c9d2a13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "We've detected an older driver with an RTX 4000 series GPU. These drivers have issues with P2P. This can affect the multi-gpu inference when using accelerate device_map.Please make sure to update your driver to the latest version which resolves this.\n"
     ]
    }
   ],
   "source": [
    "# Initializing LLM\n",
    "model_name = \"Qwen/Qwen2.5-7B-Instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=\"auto\",\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "015d7d0b-1212-4ae6-a50a-7bfb11a94196",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Explain the importance of fast language model.\"\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"You are Qwen, created by Alibaba Cloud. You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": prompt}\n",
    "]\n",
    "text = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6134607f-33c8-4bc8-b27c-0835f9316c21",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_inputs = tokenizer([text], return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "generated_ids = model.generate(\n",
    "    **model_inputs,\n",
    "    max_new_tokens=512\n",
    ")\n",
    "generated_ids = [\n",
    "    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "]\n",
    "\n",
    "response = tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "20f3796b-cd1f-4610-bea1-391af065b541",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    def __init__(self, model, tokenizer, system: str = \"\") -> None:\n",
    "            self.model = model\n",
    "            self.tokenizer = tokenizer\n",
    "            self.system = system\n",
    "            self.messages: list = []\n",
    "            if self.system:\n",
    "                self.messages.append({\"role\": \"system\", \"content\": system})\n",
    "    def __call__(self, message):\n",
    "        if message:\n",
    "            self.messages.append({\"role\": \"user\", \"content\": message})\n",
    "        result = self.execute()\n",
    "        self.messages.append({\"role\": \"assistant\", \"content\": result})\n",
    "        return result\n",
    "\n",
    "    def execute(self):\n",
    "        messages = self.messages\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
    "\n",
    "        generated_ids = self.model.generate(\n",
    "            **model_inputs,\n",
    "            max_new_tokens=512\n",
    "        )\n",
    "        generated_ids = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
    "        ]\n",
    "        \n",
    "        response = self.tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
    "        return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7651b1c5-b38d-4885-a84c-f9281662715c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt for the Agent\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You run in a loop of Thought, Action, PAUSE, Observation.\n",
    "At the end of the loop you output an Answer\n",
    "Use Thought to describe your thoughts about the question you have been asked.\n",
    "Use Action to run one of the actions available to you - then return PAUSE.\n",
    "Observation will be the result of running those actions.\n",
    "\n",
    "Your available actions are:\n",
    "\n",
    "calculate:\n",
    "e.g. calculate: 4 * 7 / 3\n",
    "Runs a calculation and returns the number - uses Python so be sure to use floating point syntax if necessary\n",
    "\n",
    "get_planet_mass:\n",
    "e.g. get_planet_mass: Earth\n",
    "returns weight of the planet in kg\n",
    "\n",
    "Example session:\n",
    "\n",
    "Question: What is the mass of Earth times 2?\n",
    "Thought: I need to find the mass of Earth\n",
    "Action: get_planet_mass: Earth\n",
    "PAUSE \n",
    "\n",
    "You will be called again with this:\n",
    "\n",
    "Observation: 5.972e24\n",
    "\n",
    "Thought: I need to multiply this by 2\n",
    "Action: calculate: 5.972e24 * 2\n",
    "PAUSE\n",
    "\n",
    "You will be called again with this: \n",
    "\n",
    "Observation: 1,1944×10e25\n",
    "\n",
    "If you have the answer, output it as the Answer.\n",
    "\n",
    "Answer: The mass of Earth times 2 is 1,1944×10e25.\n",
    "\n",
    "Now it's your turn:\n",
    "\"\"\".strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac4adfb1-781c-4997-a4f5-39c0800e637b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate(operation: str) -> float:\n",
    "    return eval(operation)\n",
    "\n",
    "\n",
    "def get_planet_mass(planet) -> float:\n",
    "    planet = planet.lower()\n",
    "    if planet == \"earth\":\n",
    "        return 5.972e24\n",
    "    if planet == \"mars\":\n",
    "        return 6.39e23\n",
    "    if planet == \"jupiter\":\n",
    "        return 1.898e27\n",
    "    if planet == \"saturn\":\n",
    "        return 5.683e26\n",
    "    if planet == \"uranus\":\n",
    "        return 8.681e25\n",
    "    if planet == \"neptune\":\n",
    "        return 1.024e26\n",
    "    if planet == \"mercury\":\n",
    "        return 3.285e23\n",
    "    if planet == \"venus\":\n",
    "        return 4.867e24\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d88137d4-6972-4563-9b5a-ca6fb6841fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query Loop\n",
    "\n",
    "def loop(max_iterations=10, query: str = \"\"):\n",
    "\n",
    "    agent =  Agent(model=model,tokenizer=tokenizer, system=system_prompt)\n",
    "\n",
    "    tools = [\"calculate\", \"get_planet_mass\"]\n",
    "\n",
    "    next_prompt = query\n",
    "\n",
    "    i = 0\n",
    "  \n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action = re.findall(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            chosen_tool = action[0][0]\n",
    "            arg = action[0][1]\n",
    "\n",
    "            if chosen_tool in tools:\n",
    "                result_tool = eval(f\"{chosen_tool}('{arg}')\")\n",
    "                next_prompt = f\"Observation: {result_tool}\"\n",
    "\n",
    "            else:\n",
    "                next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "            print(next_prompt)\n",
    "            continue\n",
    "\n",
    "        if \"Answer\" in result:\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3611d73c-5385-4e3b-8f94-0a883c9a4ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Query Loop with Action Tracking\n",
    "def loop(max_iterations=10, query: str = \"\"):\n",
    "    agent = Agent(model=model, tokenizer=tokenizer, system=system_prompt)\n",
    "    \n",
    "    tools = {\n",
    "        \"calculate\": calculate,\n",
    "        \"get_planet_mass\": get_planet_mass,\n",
    "    }\n",
    "    \n",
    "    next_prompt = query\n",
    "    i = 0\n",
    "    completed_actions = set()  # To track already completed actions\n",
    "    \n",
    "    while i < max_iterations:\n",
    "        i += 1\n",
    "        result = agent(next_prompt)\n",
    "        print(result)\n",
    "        \n",
    "        # Check if the result contains a pause and action command\n",
    "        if \"PAUSE\" in result and \"Action\" in result:\n",
    "            action_match = re.search(r\"Action: ([a-z_]+): (.+)\", result, re.IGNORECASE)\n",
    "            if action_match:\n",
    "                chosen_tool = action_match.group(1)\n",
    "                arg = action_match.group(2)\n",
    "\n",
    "                # Check if this action has already been completed to avoid repetition\n",
    "                if (chosen_tool, arg) in completed_actions:\n",
    "                    next_prompt = \"Observation: Repeated action detected, moving to the next step.\"\n",
    "                    print(next_prompt)\n",
    "                    continue\n",
    "                \n",
    "                # Execute the corresponding tool if it exists\n",
    "                if chosen_tool in tools:\n",
    "                    result_tool = tools[chosen_tool](arg)\n",
    "                    next_prompt = f\"Observation: {result_tool}\"\n",
    "                    completed_actions.add((chosen_tool, arg))  # Mark action as completed\n",
    "                else:\n",
    "                    next_prompt = \"Observation: Tool not found\"\n",
    "\n",
    "                print(next_prompt)\n",
    "                continue\n",
    "        \n",
    "        # If the agent provided an answer, end the loop\n",
    "        if \"Answer\" in result:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6b4f828a-3c90-40fc-9f7d-d816637722a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thought: First, I need to find the mass of Saturn. Then, I'll add the mass of Earth to the mass of Saturn. Finally, I'll multiply the total by 2.\n",
      "Action: get_planet_mass: Saturn\n",
      "PAUSE\n",
      "Observation: 5.683e+26\n",
      "Thought: Now that I have the mass of Saturn, I need to add it to the mass of Earth and then multiply the result by 2. I already know the mass of Earth from the previous calculation.\n",
      "Action: calculate: (5.972e24 + 5.683e26) * 2\n",
      "PAUSE\n",
      "Observation: 1.148544e+27\n",
      "Thought: The calculation is complete. The result is the mass of Earth plus the mass of Saturn, all multiplied by 2.\n",
      "Answer: The mass of Earth plus the mass of Saturn and all of that times 2 is 1.148544e+27 kg.\n"
     ]
    }
   ],
   "source": [
    "# running the query \n",
    "\n",
    "loop(query=\"What is the mass of Earth plus the mass of Saturn and all of that times 2?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f533a6-73e8-4090-8e2d-8082c9672b4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
