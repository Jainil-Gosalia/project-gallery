{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>ethnicity</th>\n",
       "      <th>gender</th>\n",
       "      <th>img_name</th>\n",
       "      <th>pixels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219203650636.jpg.chip.jpg</td>\n",
       "      <td>129 128 128 126 127 130 133 135 139 142 145 14...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222752047.jpg.chip.jpg</td>\n",
       "      <td>164 74 111 168 169 171 175 182 184 188 193 199...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161219222832191.jpg.chip.jpg</td>\n",
       "      <td>67 70 71 70 69 67 70 79 90 103 116 132 145 155...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144911423.jpg.chip.jpg</td>\n",
       "      <td>193 197 198 200 199 200 202 203 204 205 208 21...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>20161220144914327.jpg.chip.jpg</td>\n",
       "      <td>202 205 209 210 209 209 210 211 212 214 218 21...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  ethnicity  gender                        img_name  \\\n",
       "0    1          2       0  20161219203650636.jpg.chip.jpg   \n",
       "1    1          2       0  20161219222752047.jpg.chip.jpg   \n",
       "2    1          2       0  20161219222832191.jpg.chip.jpg   \n",
       "3    1          2       0  20161220144911423.jpg.chip.jpg   \n",
       "4    1          2       0  20161220144914327.jpg.chip.jpg   \n",
       "\n",
       "                                              pixels  \n",
       "0  129 128 128 126 127 130 133 135 139 142 145 14...  \n",
       "1  164 74 111 168 169 171 175 182 184 188 193 199...  \n",
       "2  67 70 71 70 69 67 70 79 90 103 116 132 145 155...  \n",
       "3  193 197 198 200 199 200 202 203 204 205 208 21...  \n",
       "4  202 205 209 210 209 209 210 211 212 214 218 21...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"age_gender.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age          0\n",
       "ethnicity    0\n",
       "gender       0\n",
       "img_name     0\n",
       "pixels       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking for NA values\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         1\n",
       "1         1\n",
       "2         1\n",
       "3         1\n",
       "4         1\n",
       "         ..\n",
       "23700    99\n",
       "23701    99\n",
       "23702    99\n",
       "23703    99\n",
       "23704    99\n",
       "Name: age, Length: 23705, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y1 = df['age']\n",
    "Y1.nunique()\n",
    "Y1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2 = df['ethnicity']\n",
    "Y2.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y3 = df['gender']\n",
    "Y3.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23705 2304\n"
     ]
    }
   ],
   "source": [
    "#Getting dimensions of pixels\n",
    "n_features = len(df.pixels[0].split())\n",
    "print(len(df.pixels), n_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spliting String into respective floats\n",
    "X=np.zeros(shape=(23705,2304))\n",
    "\n",
    "for i in range(len(df.pixels)):\n",
    "    a=np.array(df.pixels[i].split(),dtype='float32')\n",
    "    X[i]=a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2294</th>\n",
       "      <th>2295</th>\n",
       "      <th>2296</th>\n",
       "      <th>2297</th>\n",
       "      <th>2298</th>\n",
       "      <th>2299</th>\n",
       "      <th>2300</th>\n",
       "      <th>2301</th>\n",
       "      <th>2302</th>\n",
       "      <th>2303</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552527</td>\n",
       "      <td>0.595723</td>\n",
       "      <td>0.630926</td>\n",
       "      <td>0.608607</td>\n",
       "      <td>0.603081</td>\n",
       "      <td>0.598330</td>\n",
       "      <td>0.573887</td>\n",
       "      <td>0.513939</td>\n",
       "      <td>0.477998</td>\n",
       "      <td>0.430440</td>\n",
       "      <td>...</td>\n",
       "      <td>0.284915</td>\n",
       "      <td>0.361761</td>\n",
       "      <td>0.418779</td>\n",
       "      <td>0.464353</td>\n",
       "      <td>0.506114</td>\n",
       "      <td>0.518489</td>\n",
       "      <td>0.501318</td>\n",
       "      <td>0.517149</td>\n",
       "      <td>0.509225</td>\n",
       "      <td>0.497893</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.048430</td>\n",
       "      <td>-0.195187</td>\n",
       "      <td>0.374738</td>\n",
       "      <td>1.258430</td>\n",
       "      <td>1.266118</td>\n",
       "      <td>1.255450</td>\n",
       "      <td>1.257678</td>\n",
       "      <td>1.289544</td>\n",
       "      <td>1.230453</td>\n",
       "      <td>1.211948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.953061</td>\n",
       "      <td>1.236372</td>\n",
       "      <td>1.691311</td>\n",
       "      <td>1.915790</td>\n",
       "      <td>1.811414</td>\n",
       "      <td>1.723120</td>\n",
       "      <td>1.312273</td>\n",
       "      <td>0.997706</td>\n",
       "      <td>0.827259</td>\n",
       "      <td>0.524186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.325930</td>\n",
       "      <td>-0.253773</td>\n",
       "      <td>-0.228056</td>\n",
       "      <td>-0.257824</td>\n",
       "      <td>-0.312541</td>\n",
       "      <td>-0.411391</td>\n",
       "      <td>-0.451799</td>\n",
       "      <td>-0.410187</td>\n",
       "      <td>-0.341342</td>\n",
       "      <td>-0.232143</td>\n",
       "      <td>...</td>\n",
       "      <td>0.195829</td>\n",
       "      <td>0.128532</td>\n",
       "      <td>0.161413</td>\n",
       "      <td>0.154337</td>\n",
       "      <td>0.158959</td>\n",
       "      <td>0.148886</td>\n",
       "      <td>0.109357</td>\n",
       "      <td>0.063290</td>\n",
       "      <td>0.045425</td>\n",
       "      <td>-0.001670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.459321</td>\n",
       "      <td>1.606330</td>\n",
       "      <td>1.685816</td>\n",
       "      <td>1.753534</td>\n",
       "      <td>1.739716</td>\n",
       "      <td>1.720242</td>\n",
       "      <td>1.697258</td>\n",
       "      <td>1.636091</td>\n",
       "      <td>1.564878</td>\n",
       "      <td>1.500766</td>\n",
       "      <td>...</td>\n",
       "      <td>1.695445</td>\n",
       "      <td>1.717408</td>\n",
       "      <td>1.748504</td>\n",
       "      <td>1.732599</td>\n",
       "      <td>1.700325</td>\n",
       "      <td>1.695742</td>\n",
       "      <td>1.677203</td>\n",
       "      <td>1.705193</td>\n",
       "      <td>1.741608</td>\n",
       "      <td>1.812533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.586839</td>\n",
       "      <td>1.723502</td>\n",
       "      <td>1.851584</td>\n",
       "      <td>1.908253</td>\n",
       "      <td>1.897582</td>\n",
       "      <td>1.864488</td>\n",
       "      <td>1.827504</td>\n",
       "      <td>1.768109</td>\n",
       "      <td>1.698648</td>\n",
       "      <td>1.653670</td>\n",
       "      <td>...</td>\n",
       "      <td>0.908518</td>\n",
       "      <td>0.915681</td>\n",
       "      <td>0.890617</td>\n",
       "      <td>0.873010</td>\n",
       "      <td>0.867154</td>\n",
       "      <td>0.888092</td>\n",
       "      <td>0.866248</td>\n",
       "      <td>0.797474</td>\n",
       "      <td>0.734499</td>\n",
       "      <td>0.695089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 2304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0         1         2         3         4         5         6     \\\n",
       "0  0.552527  0.595723  0.630926  0.608607  0.603081  0.598330  0.573887   \n",
       "1  1.048430 -0.195187  0.374738  1.258430  1.266118  1.255450  1.257678   \n",
       "2 -0.325930 -0.253773 -0.228056 -0.257824 -0.312541 -0.411391 -0.451799   \n",
       "3  1.459321  1.606330  1.685816  1.753534  1.739716  1.720242  1.697258   \n",
       "4  1.586839  1.723502  1.851584  1.908253  1.897582  1.864488  1.827504   \n",
       "\n",
       "       7         8         9     ...      2294      2295      2296      2297  \\\n",
       "0  0.513939  0.477998  0.430440  ...  0.284915  0.361761  0.418779  0.464353   \n",
       "1  1.289544  1.230453  1.211948  ...  0.953061  1.236372  1.691311  1.915790   \n",
       "2 -0.410187 -0.341342 -0.232143  ...  0.195829  0.128532  0.161413  0.154337   \n",
       "3  1.636091  1.564878  1.500766  ...  1.695445  1.717408  1.748504  1.732599   \n",
       "4  1.768109  1.698648  1.653670  ...  0.908518  0.915681  0.890617  0.873010   \n",
       "\n",
       "       2298      2299      2300      2301      2302      2303  \n",
       "0  0.506114  0.518489  0.501318  0.517149  0.509225  0.497893  \n",
       "1  1.811414  1.723120  1.312273  0.997706  0.827259  0.524186  \n",
       "2  0.158959  0.148886  0.109357  0.063290  0.045425 -0.001670  \n",
       "3  1.700325  1.695742  1.677203  1.705193  1.741608  1.812533  \n",
       "4  0.867154  0.888092  0.866248  0.797474  0.734499  0.695089  \n",
       "\n",
       "[5 rows x 2304 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Feature Scaling and Standardization\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "X = pd.DataFrame(X)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16593, 2304]) torch.Size([16593])\n",
      "torch.Size([7112, 2304]) torch.Size([7112])\n"
     ]
    }
   ],
   "source": [
    "#Test train split\n",
    "X1_train, X1_test, y1_train, y1_test = train_test_split(X, Y1, test_size=0.3, random_state=42)\n",
    "X2_train, X2_test, y2_train, y2_test = train_test_split(X, Y2, test_size=0.3, random_state=42)\n",
    "X3_train, X3_test, y3_train, y3_test = train_test_split(X, Y3, test_size=0.3, random_state=42)\n",
    "\n",
    "#Converting dataframes to tensor for pytorch\n",
    "X3_train = torch.from_numpy(X3_train.to_numpy()).float()\n",
    "y3_train = torch.squeeze(torch.from_numpy(y3_train.to_numpy()).float())\n",
    "X3_test = torch.from_numpy(X3_test.to_numpy()).float()\n",
    "y3_test = torch.squeeze(torch.from_numpy(y3_test.to_numpy()).float())\n",
    "\n",
    "print(X3_train.shape, y3_train.shape)\n",
    "print(X3_test.shape, y3_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural_Net_Gender(\n",
      "  (fc1): Linear(in_features=2304, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "#Defining Neural Network for Gender\n",
    "class Neural_Net_Gender(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Neural_Net_Gender, self).__init__()\n",
    "        self.fc1 = nn.Linear(2304, 64)\n",
    "        self.fc2 = nn.Linear(64, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "net = Neural_Net_Gender()\n",
    "print(net)\n",
    "\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1.,  ..., 1., 0., 1.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y3_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\\n\\nX3_train = X3_train.to(device)\\ny3_train = y3_train.to(device)\\n\\nX3_test = X3_test.to(device)\\ny3_test = y3_test.to(device)\\n\\nnet = net.to(device)\\n\\nloss_function = loss_function.to(device)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use if you want to use GPU\n",
    "'''\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "X3_train = X3_train.to(device)\n",
    "y3_train = y3_train.to(device)\n",
    "\n",
    "X3_test = X3_test.to(device)\n",
    "y3_test = y3_test.to(device)\n",
    "\n",
    "net = net.to(device)\n",
    "\n",
    "loss_function = loss_function.to(device)'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy Functions\n",
    "def calculate_accuracy(y_true, y_pred):\n",
    "    predicted = y_pred.ge(.5).view(-1)\n",
    "    return (y_true == predicted).sum().float() / len(y_true)\n",
    "def round_tensor(t, decimal_places=3):\n",
    "    return round(t.item(), decimal_places)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "            Train set - loss: 0.707, accuracy: 0.476\n",
      "            Test  set - loss: 0.706, accuracy: 0.477\n",
      "            \n",
      "epoch 100\n",
      "            Train set - loss: 4.834, accuracy: 0.826\n",
      "            Test  set - loss: 4.957, accuracy: 0.823\n",
      "            \n",
      "epoch 200\n",
      "            Train set - loss: 3.949, accuracy: 0.858\n",
      "            Test  set - loss: 4.364, accuracy: 0.844\n",
      "            \n",
      "epoch 300\n",
      "            Train set - loss: 3.96, accuracy: 0.857\n",
      "            Test  set - loss: 4.322, accuracy: 0.844\n",
      "            \n",
      "epoch 400\n",
      "            Train set - loss: 3.615, accuracy: 0.87\n",
      "            Test  set - loss: 4.175, accuracy: 0.849\n",
      "            \n",
      "epoch 500\n",
      "            Train set - loss: 3.084, accuracy: 0.889\n",
      "            Test  set - loss: 3.833, accuracy: 0.861\n",
      "            \n",
      "epoch 600\n",
      "            Train set - loss: 3.15, accuracy: 0.886\n",
      "            Test  set - loss: 3.957, accuracy: 0.857\n",
      "            \n",
      "epoch 700\n",
      "            Train set - loss: 2.784, accuracy: 0.899\n",
      "            Test  set - loss: 3.824, accuracy: 0.863\n",
      "            \n",
      "epoch 800\n",
      "            Train set - loss: 3.008, accuracy: 0.892\n",
      "            Test  set - loss: 3.92, accuracy: 0.859\n",
      "            \n",
      "epoch 900\n",
      "            Train set - loss: 2.996, accuracy: 0.893\n",
      "            Test  set - loss: 3.937, accuracy: 0.859\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "#Model Training for Gender\n",
    "for i in range(1000):\n",
    "    y_pred = net(X3_train)\n",
    "    y_pred = torch.squeeze(y_pred)\n",
    "    train_loss = loss_function(y_pred, y3_train)\n",
    "    \n",
    "    if i % 100 == 0:\n",
    "        train_acc = calculate_accuracy(y3_train, y_pred)\n",
    "\n",
    "        y_test_pred = net(X3_test)\n",
    "        y_test_pred = torch.squeeze(y_test_pred)\n",
    "\n",
    "        test_loss = loss_function(y_test_pred, y3_test)\n",
    "\n",
    "        test_acc = calculate_accuracy(y3_test, y_test_pred)\n",
    "        print(\n",
    "            f'''epoch {i}\n",
    "            Train set - loss: {round_tensor(train_loss)}, accuracy: {round_tensor(train_acc)}\n",
    "            Test  set - loss: {round_tensor(test_loss)}, accuracy: {round_tensor(test_acc)}\n",
    "            ''')\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    train_loss.backward()\n",
    "    \n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Jainil\\anaconda3\\lib\\site-packages\\torch\\serialization.py:359: UserWarning: Couldn't retrieve source code for container of type Neural_Net_Gender. It won't be checked for correctness upon loading.\n",
      "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
     ]
    }
   ],
   "source": [
    "#Saving the Model\n",
    "MODEL_PATH = 'model.pth'\n",
    "torch.save(net, MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reloading the Model\n",
    "net = torch.load(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.79      0.85      3741\n",
      "         1.0       0.80      0.92      0.86      3371\n",
      "\n",
      "    accuracy                           0.85      7112\n",
      "   macro avg       0.86      0.86      0.85      7112\n",
      "weighted avg       0.86      0.85      0.85      7112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Results for gender\n",
    "y_pred = net(X3_test)\n",
    "y_pred = y_pred.ge(.5).view(-1).cpu()\n",
    "y3_test = y3_test.cpu()\n",
    "\n",
    "print(classification_report(y3_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
